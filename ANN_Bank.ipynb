{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Bank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritzz19/Bank_churn_ANN/blob/master/ANN_Bank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxSHnjL8Oya5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the libraries \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSpZn6ZMRNuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the datasets\n",
        "dataset=pd.read_csv('Churn_Modelling.csv')\n",
        "X=dataset.iloc[:,3:13].values\n",
        "y=dataset.iloc[:,13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbx2zmOyXsD3",
        "colab_type": "code",
        "outputId": "3b1f04b0-bd02-45e5-9df8-a192693d7a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Encoding categorical dataset\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "labelencoder_X_1=LabelEncoder()\n",
        "X[:, 1]=labelencoder_X_1.fit_transform(X[:,1])\n",
        "labelencoder_X_2=LabelEncoder()\n",
        "X[:, 2]=labelencoder_X_2.fit_transform(X[:,2])\n",
        "onehotencoder=OneHotEncoder(categorical_features=[1])\n",
        "X=onehotencoder.fit_transform(X).toarray()\n",
        "X=X[:,1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdh1eiBMRrAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.35,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY80G9cKSNz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CznxtfusbE69",
        "colab_type": "text"
      },
      "source": [
        "Making ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMWrpsYdTQ8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the keras libraries\n",
        "import keras\n",
        "from keras.models import Sequential #initialize inputs\n",
        "from keras.layers import Dense #create layers in ANN(Hidden layers)\n",
        "from keras.layers import Dropout #for avoiding overfitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdFsG-rWVkXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialising the ANN\n",
        "classifier=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne6qaTAGcRDe",
        "colab_type": "code",
        "outputId": "dfa21ada-7346-4a03-dd73-99105fcc0d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Adding the input layer and first hidden layer\n",
        "classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11))\n",
        "classifier.add(Dropout(p=0.1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8aNIFmA2y3",
        "colab_type": "code",
        "outputId": "bbb805da-ac1c-4a6f-8b59-a116db1542d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#Adding the second hidden layer\n",
        "classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
        "classifier.add(Dropout(p=0.1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "map-mjocBh78",
        "colab_type": "code",
        "outputId": "27fc37e1-47c7-478d-b384-7a27db3e2516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Adding the output layer\n",
        "classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M115YEazC8GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling the ANN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glg12HzJEMLQ",
        "colab_type": "code",
        "outputId": "d2fcb166-c6b4-4e6f-ce2f-6ef67f4c4bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Fitting the ANN to the training set\n",
        "classifier.fit(X_train,y_train, batch_size=10, nb_epoch=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6500/6500 [==============================] - 1s 138us/step - loss: 0.5017 - acc: 0.7972\n",
            "Epoch 2/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.4305 - acc: 0.7975\n",
            "Epoch 3/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4269 - acc: 0.7975\n",
            "Epoch 4/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4235 - acc: 0.7975\n",
            "Epoch 5/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4200 - acc: 0.7977\n",
            "Epoch 6/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.4175 - acc: 0.8226\n",
            "Epoch 7/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4157 - acc: 0.8263\n",
            "Epoch 8/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.4148 - acc: 0.8260\n",
            "Epoch 9/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4134 - acc: 0.8285\n",
            "Epoch 10/100\n",
            "6500/6500 [==============================] - 1s 112us/step - loss: 0.4124 - acc: 0.8300\n",
            "Epoch 11/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.4118 - acc: 0.8306\n",
            "Epoch 12/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.4107 - acc: 0.8306\n",
            "Epoch 13/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.4102 - acc: 0.8317\n",
            "Epoch 14/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.4098 - acc: 0.8317\n",
            "Epoch 15/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.4086 - acc: 0.8328\n",
            "Epoch 16/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4084 - acc: 0.8331\n",
            "Epoch 17/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4076 - acc: 0.8326\n",
            "Epoch 18/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.4071 - acc: 0.8343\n",
            "Epoch 19/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4066 - acc: 0.8337\n",
            "Epoch 20/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4060 - acc: 0.8337\n",
            "Epoch 21/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.4056 - acc: 0.8328\n",
            "Epoch 22/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.4056 - acc: 0.8342\n",
            "Epoch 23/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4049 - acc: 0.8342\n",
            "Epoch 24/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4048 - acc: 0.8338\n",
            "Epoch 25/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.4040 - acc: 0.8354\n",
            "Epoch 26/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4027 - acc: 0.8351\n",
            "Epoch 27/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4026 - acc: 0.8342\n",
            "Epoch 28/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.4017 - acc: 0.8343\n",
            "Epoch 29/100\n",
            "6500/6500 [==============================] - 1s 103us/step - loss: 0.4011 - acc: 0.8338\n",
            "Epoch 30/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4013 - acc: 0.8340\n",
            "Epoch 31/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.4010 - acc: 0.8343\n",
            "Epoch 32/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.3997 - acc: 0.8351\n",
            "Epoch 33/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3993 - acc: 0.8338\n",
            "Epoch 34/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3998 - acc: 0.8338\n",
            "Epoch 35/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3989 - acc: 0.8362\n",
            "Epoch 36/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3983 - acc: 0.8335\n",
            "Epoch 37/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3979 - acc: 0.8351\n",
            "Epoch 38/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.3980 - acc: 0.8352\n",
            "Epoch 39/100\n",
            "6500/6500 [==============================] - 1s 110us/step - loss: 0.3973 - acc: 0.8351\n",
            "Epoch 40/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.3972 - acc: 0.8348\n",
            "Epoch 41/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3969 - acc: 0.8338\n",
            "Epoch 42/100\n",
            "6500/6500 [==============================] - 1s 111us/step - loss: 0.3971 - acc: 0.8338\n",
            "Epoch 43/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3968 - acc: 0.8337\n",
            "Epoch 44/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3966 - acc: 0.8332\n",
            "Epoch 45/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3956 - acc: 0.8326\n",
            "Epoch 46/100\n",
            "6500/6500 [==============================] - 1s 111us/step - loss: 0.3962 - acc: 0.8358\n",
            "Epoch 47/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.3959 - acc: 0.8340\n",
            "Epoch 48/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3958 - acc: 0.8332\n",
            "Epoch 49/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3961 - acc: 0.8337\n",
            "Epoch 50/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3961 - acc: 0.8329\n",
            "Epoch 51/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3963 - acc: 0.8354\n",
            "Epoch 52/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3952 - acc: 0.8352\n",
            "Epoch 53/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3955 - acc: 0.8357\n",
            "Epoch 54/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3951 - acc: 0.8352\n",
            "Epoch 55/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3958 - acc: 0.8335\n",
            "Epoch 56/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3953 - acc: 0.8342\n",
            "Epoch 57/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3957 - acc: 0.8345\n",
            "Epoch 58/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3957 - acc: 0.8346\n",
            "Epoch 59/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3959 - acc: 0.8335\n",
            "Epoch 60/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3952 - acc: 0.8340\n",
            "Epoch 61/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.3951 - acc: 0.8342\n",
            "Epoch 62/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3949 - acc: 0.8340\n",
            "Epoch 63/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3953 - acc: 0.8369\n",
            "Epoch 64/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3951 - acc: 0.8354\n",
            "Epoch 65/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3951 - acc: 0.8340\n",
            "Epoch 66/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3950 - acc: 0.8349\n",
            "Epoch 67/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3945 - acc: 0.8357\n",
            "Epoch 68/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3951 - acc: 0.8337\n",
            "Epoch 69/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.3951 - acc: 0.8354\n",
            "Epoch 70/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3947 - acc: 0.8343\n",
            "Epoch 71/100\n",
            "6500/6500 [==============================] - 1s 110us/step - loss: 0.3951 - acc: 0.8334\n",
            "Epoch 72/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3952 - acc: 0.8334\n",
            "Epoch 73/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.3944 - acc: 0.8357\n",
            "Epoch 74/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3947 - acc: 0.8358\n",
            "Epoch 75/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3947 - acc: 0.8346\n",
            "Epoch 76/100\n",
            "6500/6500 [==============================] - 1s 111us/step - loss: 0.3952 - acc: 0.8346\n",
            "Epoch 77/100\n",
            "6500/6500 [==============================] - 1s 112us/step - loss: 0.3951 - acc: 0.8340\n",
            "Epoch 78/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3949 - acc: 0.8345\n",
            "Epoch 79/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3950 - acc: 0.8355\n",
            "Epoch 80/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3945 - acc: 0.8348\n",
            "Epoch 81/100\n",
            "6500/6500 [==============================] - 1s 110us/step - loss: 0.3948 - acc: 0.8322\n",
            "Epoch 82/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.3945 - acc: 0.8331\n",
            "Epoch 83/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3938 - acc: 0.8355\n",
            "Epoch 84/100\n",
            "6500/6500 [==============================] - 1s 107us/step - loss: 0.3943 - acc: 0.8351\n",
            "Epoch 85/100\n",
            "6500/6500 [==============================] - 1s 105us/step - loss: 0.3943 - acc: 0.8332\n",
            "Epoch 86/100\n",
            "6500/6500 [==============================] - 1s 109us/step - loss: 0.3945 - acc: 0.8358\n",
            "Epoch 87/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3944 - acc: 0.8360\n",
            "Epoch 88/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3945 - acc: 0.8358\n",
            "Epoch 89/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3934 - acc: 0.8366\n",
            "Epoch 90/100\n",
            "6500/6500 [==============================] - 1s 114us/step - loss: 0.3941 - acc: 0.8338\n",
            "Epoch 91/100\n",
            "6500/6500 [==============================] - 1s 104us/step - loss: 0.3942 - acc: 0.8338\n",
            "Epoch 92/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3939 - acc: 0.8354\n",
            "Epoch 93/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3942 - acc: 0.8348\n",
            "Epoch 94/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3939 - acc: 0.8338\n",
            "Epoch 95/100\n",
            "6500/6500 [==============================] - 1s 106us/step - loss: 0.3937 - acc: 0.8365\n",
            "Epoch 96/100\n",
            "6500/6500 [==============================] - 1s 111us/step - loss: 0.3939 - acc: 0.8349\n",
            "Epoch 97/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3934 - acc: 0.8348\n",
            "Epoch 98/100\n",
            "6500/6500 [==============================] - 1s 111us/step - loss: 0.3939 - acc: 0.8342\n",
            "Epoch 99/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3937 - acc: 0.8346\n",
            "Epoch 100/100\n",
            "6500/6500 [==============================] - 1s 108us/step - loss: 0.3939 - acc: 0.8348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f575c03ddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQGWE4r1FyfW",
        "colab_type": "text"
      },
      "source": [
        "### Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl4Et_o9FEBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the test set results\n",
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=(y_pred>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p2xnQpEd294",
        "colab_type": "code",
        "outputId": "9b36438d-bcaa-4adc-ac1b-5b43231ff921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8gWs6IaGPpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making the confusion matix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMbF_RgdzXY",
        "colab_type": "code",
        "outputId": "435bf9fd-7868-41e0-ea38-d724a30064bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2691,   88],\n",
              "       [ 471,  250]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ULEOOSHicB",
        "colab_type": "text"
      },
      "source": [
        "Predicting\n",
        "1.Geography:France\n",
        "2.Credit score: 600\n",
        "3.Gender: Male\n",
        "4.Age: 40 years old\n",
        "5.Tenture: 3 years\n",
        "6.Balance: $60000\n",
        "7.Number of products: 2\n",
        "8.Does this customer have a credit card?: Yes\n",
        "9.Is this customer an ative member: Yes\n",
        "10.Estimates Salary= $50000 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuMFJSzTGxhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_prediction = classifier.predict(sc.transform(np.array([[0, 0, 600, 1, 40, 3, 60000, 2,1,1, 50000]])))\n",
        "new_prediction=(new_prediction>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCTuaeoPdoq-",
        "colab_type": "code",
        "outputId": "507b76c6-4002-4307-86dc-6e5139e79a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Z87hbmeWBp",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating, Improving and Tuning ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-_-YQ_QduY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier #combining keras and scikit learn\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def build_classifier(): #kerasClassifier expect one of its arument as function Build the architecture of our ANN)\n",
        "  classifier=Sequential()\n",
        "  classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11))\n",
        "  classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
        "  classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n",
        "  classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size=10,nb_epoch=100) #global\n",
        "accuracies=cross_val_score(estimator=classifier, X=X_train, y=y_train,cv=10,n_jobs=-1)\n",
        "mean=accuracies.mean()\n",
        "variance=accuracies.std()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKq-xGJhwXld",
        "colab_type": "code",
        "outputId": "585cb67a-0695-491f-e614-7826e7a6f807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7975384582006014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gezmyCMSzzUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Improving the ANN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwG7QMn47WG5",
        "colab_type": "code",
        "outputId": "21cc7c4b-3b06-40a6-ae48-e247970ed8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Tuning the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier #combining keras and scikit learn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier(optimizer): #kerasClassifier expect one of its arument as function Build the architecture of our ANN)\n",
        "  classifier=Sequential()\n",
        "  classifier.add(Dense(output_dim=6,init='uniform',activation='relu',input_dim=11))\n",
        "  classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
        "  classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))\n",
        "  classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier) #global\n",
        "parameters = {'batch_size':[25,32],\n",
        "              'nb_epoch':[100,500],\n",
        "              'optimizer':['adam','rmsprop']}\n",
        "grid_search=GridSearchCV(estimator=classifier,\n",
        "                         param_grid=parameters,\n",
        "                         scoring='accuracy',\n",
        "                         cv=10)\n",
        "grid_search=grid_search.fit(X_train,y_train)\n",
        "best_parameters=grid_search.best_params_\n",
        "best_accuracy=grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 6s 1ms/step - loss: 0.5833 - acc: 0.7993\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 6s 1ms/step - loss: 0.5725 - acc: 0.7959\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 6s 1ms/step - loss: 0.5906 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 6s 1ms/step - loss: 0.5750 - acc: 0.7950\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5816 - acc: 0.7971\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5694 - acc: 0.7985\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5875 - acc: 0.7988\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5676 - acc: 0.7976\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5980 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5711 - acc: 0.7969\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6059 - acc: 0.7995\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6185 - acc: 0.7952\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6248 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6013 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5942 - acc: 0.7952\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6089 - acc: 0.7973\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.5938 - acc: 0.7990\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 7s 1ms/step - loss: 0.6027 - acc: 0.7971\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.6035 - acc: 0.7971\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.5763 - acc: 0.7968\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.5831 - acc: 0.7988\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.5907 - acc: 0.7937\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.5723 - acc: 0.7974\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.5735 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 8s 1ms/step - loss: 0.6628 - acc: 0.7937\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 1ms/step - loss: 0.5704 - acc: 0.7985\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 1ms/step - loss: 0.5865 - acc: 0.7973\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 1ms/step - loss: 0.6071 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 1ms/step - loss: 0.5894 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6001 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6088 - acc: 0.7986\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6244 - acc: 0.7947\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5951 - acc: 0.7976\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6024 - acc: 0.7940\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6021 - acc: 0.7949\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.6164 - acc: 0.7966\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5884 - acc: 0.7983\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5861 - acc: 0.7976\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5970 - acc: 0.7973\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5972 - acc: 0.7938\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 9s 2ms/step - loss: 0.5997 - acc: 0.7990\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6126 - acc: 0.7952\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6145 - acc: 0.7950\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6186 - acc: 0.7933\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6418 - acc: 0.7945\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6140 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6154 - acc: 0.7969\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6264 - acc: 0.7952\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6149 - acc: 0.7971\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6295 - acc: 0.7962\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6181 - acc: 0.7981\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6118 - acc: 0.7959\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6400 - acc: 0.7949\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6296 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 10s 2ms/step - loss: 0.6326 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6230 - acc: 0.7962\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6181 - acc: 0.7981\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6228 - acc: 0.7968\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6198 - acc: 0.7962\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6267 - acc: 0.7940\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6172 - acc: 0.7990\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6177 - acc: 0.7945\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6089 - acc: 0.7973\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6338 - acc: 0.7935\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 11s 2ms/step - loss: 0.6438 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6040 - acc: 0.7981\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6131 - acc: 0.7978\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6074 - acc: 0.7976\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6272 - acc: 0.7940\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.5992 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6117 - acc: 0.7991\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6060 - acc: 0.7959\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6160 - acc: 0.7968\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6104 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6189 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6159 - acc: 0.7978\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6082 - acc: 0.7990\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6291 - acc: 0.7952\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6212 - acc: 0.7968\n",
            "Epoch 1/1\n",
            "5850/5850 [==============================] - 12s 2ms/step - loss: 0.6666 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "6500/6500 [==============================] - 13s 2ms/step - loss: 0.5773 - acc: 0.7955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv8HMF168wvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}